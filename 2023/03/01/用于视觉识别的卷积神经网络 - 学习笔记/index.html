<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="baidu-site-verification" content="093lY4ziMu" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="description" content="Tan&#39;s Blog">
    <meta name="keyword"  content="Hello world">
    <link rel="shortcut icon" href="/img/ironman-draw.png">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <!--<link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>-->
    <title>
        
          用于视觉识别的卷积神经网络 - 学习笔记 - Tan&#39;s Blog
        
    </title>

    <link rel="canonical" href="https://master-tan.github.io/2023/03/01/用于视觉识别的卷积神经网络 - 学习笔记/">

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS --> 
    
        
<link rel="stylesheet" href="/css/dusign-light.css">

        
<link rel="stylesheet" href="/css/dusign-common-light.css">

        
<link rel="stylesheet" href="/css/font-awesome.css">

        
<link rel="stylesheet" href="/css/toc.css">

        <!-- background effects end -->
    
    
    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    
<link rel="stylesheet" href="/css/widget.css">


    
<link rel="stylesheet" href="/css/rocket.css">


    
<link rel="stylesheet" href="/css/signature.css">


    
<link rel="stylesheet" href="/css/fonts.googleapis.css">


    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">

    <!-- photography -->
    
<link rel="stylesheet" href="/css/photography.css">


    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- background effects start -->
    
    <!-- background effects end -->

	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            
                background-image: linear-gradient(rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3)), url('../../../../img/default.jpg')
                /*post*/
            
        
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
                            
                        </div>
                        <h1>用于视觉识别的卷积神经网络 - 学习笔记</h1>
                        <h2 class="subheading">Stanford University CS231n, Spring 2017</h2>
                        <span class="meta">
                            Posted by Tan on
                            2023-03-01
                        </span>

	       
                            <div class="blank_box"></div>
                            <span class="meta">
                                 <span class="post-count">3.3k</span> Words
                            </span>
                            <div class="blank_box"></div>
                            <!-- 不蒜子统计 start -->
                            <span class="meta">
                                Viewed <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span> Times
                            </span>
                            <!-- 不蒜子统计 end -->
                        

                    </div>
                

                </div>
            </div>
        </div>      
    </div>

    
    <div class="waveWrapper">
        <div class="wave wave_before" style="background-image: url('/img/wave-light.png')"></div>
        <div class="wave wave_after" style="background-image: url('/img/wave-light.png')"></div>
    </div>
    
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Tan&#39;s Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        	<li>
                          	  <a href="/archive/">Archives</a>
                        	</li>
                        
                    

                        
                    

                        
                        	<li>
                          	  <a href="/about/">About Tan</a>
                        	</li>
                        
                    

                        
                        	<li>
                          	  <a href="/tags/">Tags</a>
                        	</li>
                        
                    

                        
                    

                        
                    

                        
                    
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    <!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <p><a href='https://www.youtube.com/playlist?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk' target="_blank" rel="noopener">课程视频：https://www.youtube.com/playlist?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk</a></p>
<p><a href='http://cs231n.stanford.edu/2017' target="_blank" rel="noopener">课程网站：http://cs231n.stanford.edu/2017</a></p>
<hr>
<h3 id="Lecture-1-Introduction-to-Convolutional-Neural-Networks-for-Visual-Recognition"><a href="#Lecture-1-Introduction-to-Convolutional-Neural-Networks-for-Visual-Recognition" class="headerlink" title="Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition"></a>Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition</h3><ul>
<li>机器学习/卷积神经网络发展史及其应用</li>
</ul>
<hr>
<h3 id="Lecture-2-Image-Classification"><a href="#Lecture-2-Image-Classification" class="headerlink" title="Lecture 2 | Image Classification"></a>Lecture 2 | Image Classification</h3><ul>
<li><p>识别图像的复杂性</p>
</li>
<li><p>思考方式：数据驱动方法</p>
</li>
<li><p>图像分类对计算机为什么很难：计算机和人类“看到”的事物的语义鸿沟</p>
</li>
<li><p>k-最近邻分类器：学习决策边界</p>
</li>
<li><p>训练集-验证集-测试集</p>
</li>
<li><p>CIFAR-10：10个类别，32*32图片</p>
</li>
<li><p>交叉验证、设置超参数</p>
</li>
<li><p>线性分类：</p>
<ul>
<li>参数矩阵W（保存所有特征），图像拉伸的长向量x<script type="math/tex; mode=display">
    f(x,M) = M \cdot x + b</script></li>
<li>分数值越大，越可能属于此类</li>
<li>学习可视化：将矩阵中的对应每一类的模板，对应于图像的像素值和该类的值之间的权重，取出该行并将其展开为图像</li>
<li>一种解释：学习某个高维空间中像素之间的线性决策边界，其中空间的维度对应于图像的像素强度值</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Lecture-3-Loss-Functions-and-Optimization"><a href="#Lecture-3-Loss-Functions-and-Optimization" class="headerlink" title="Lecture 3 | Loss Functions and Optimization"></a>Lecture 3 | Loss Functions and Optimization</h3><ul>
<li><p>如何评价 $M$ 的好坏：损失函数 $L$ (数据集中N个示例中每个示例的你给个数据集中损失的平均值)(量化不同错误的严重程度)</p>
<script type="math/tex; mode=display">L=\frac{1}{N} \sum_{i} L_{i}\left(f\left(x_{i}, W\right), y_{i}\right)</script><script type="math/tex; mode=display">W_{best} \rightarrow L_{min}</script></li>
<li><p>多类 SVM 损失: (铰链损失)<br>the SVM loss has the form:</p>
</li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
L_{i} & =\sum_{j \neq y_{i}}\left\{\begin{array}{ll}
0 & \text { if } s_{y_{i}} \geq s_{j}+1 \ \ (1:设置的安全边际分数) \\
s_{j}-s_{y_{i}}+1 & \text { otherwise }
\end{array}\right. \\
& =\sum_{j \neq y_{i}} \max \left(0, s_{j}-s_{y_{i}}+1\right)
\end{aligned}</script><p>the SVM loss has the form:</p>
<script type="math/tex; mode=display">
L_{i}=\sum_{j \neq y_{i}} \max \left(0, s_{j}-s_{y_{i}}+1\right)</script><p>Loss over full dataset is average:</p>
<script type="math/tex; mode=display">
L=\frac{1}{N} \sum_{i=1}^{N} L_{i}</script><ul>
<li><p>机器学习 $\neq$ 拟合训练数据，其真正关心的是在训练出的分类器在测试数据上的性能</p>
</li>
<li><p>正则化惩罚项（Regularization）：鼓励模型以某种方式选择更“简单”的W（奥卡姆剃刀原则），以便更好的泛化</p>
<script type="math/tex; mode=display">
  \lambda R(W)</script><p>$\lambda$:正则化强度（超参数），权衡损失项和正则化项</p>
</li>
<li><p>简化模型方法</p>
<ol>
<li>限制模型类不包含更强大、更复杂的模型</li>
<li>在模型仍然可以访问更复杂模型的地方添加软惩罚</li>
</ol>
</li>
<li><p>$R(W)$:</p>
<ul>
<li>L2 regularization: $R(W)=\sum<em>{k} \sum</em>{l} W_{k, l}^{2}$</li>
<li>L1 regularization等等  </li>
</ul>
</li>
<li><p>Softmax 损失（多项逻辑回归）:对s取指数（保证非负），然后归一化（计算概率）</p>
<script type="math/tex; mode=display">
  P\left(Y=k \mid X=x_{i}\right)=\frac{e^{s_{k}}}{\sum_{j} e^{s_{j}}} \quad \text { where } \quad s=f\left(x_{i} ; W\right)</script><script type="math/tex; mode=display">
\begin{aligned}
L_{i} & = -\log P\left(Y=y_{i} \mid X=x_{i}\right)\\
  &= -\log \left(\frac{e^{s_{y_i}}}{\sum_{j} e^{s_{j}}} \right)
\end{aligned}</script><p>在这个公式上，在计算机中，$L_i$ 最小值只会趋于零而不等于零（计算机没有正无穷），最大值同理</p>
</li>
<li><p>两者效用在大多数深度学习样例中相同</p>
</li>
<li><p>优化： -&gt; 迭代</p>
<ol>
<li>随机选W （不要使用！）</li>
<li>计算函数梯度，然后使用这些梯度迭代更新参数向量 （容易出错）<ul>
<li>计算梯度：<ol>
<li>数值梯度：有限差分法（太慢）</li>
<li>解析梯度：对loss的表达式求梯度<br>不使用数值梯度作为迭代中的计算，但可以把数值计算作为一种单元测试确保解析梯度的计算正确性（一种调试策略）</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<ul>
<li><p>梯度下降法<br>向负梯度方向迭代，迭代步长 $\rightarrow$ 学习率（超参数）（最重要）<br>迭代方式：多种多样</p>
</li>
<li><p>随机梯度下降<br>实际N很大，迭代所需计算太慢，解决方法：迭代时抽取一些小型训练示例集（惯例为2的幂，如32，64，128），通过小的训练集来计算全和的估计值以及真实梯度的估计值</p>
</li>
<li><p>二阶段方法<br>图像 $\rightarrow$ 计算图像的各种特征表示 $\rightarrow$ 连接不同的特征表示后送入线性分类器</p>
<ul>
<li>e.p:颜色直方图，定向边缘直方图等</li>
<li>词袋：建立“单词本”(视觉词集) $\rightarrow$ 解析图片（建立直方图）</li>
</ul>
</li>
<li><p>特征提取器 $\stackrel{链接}{\longrightarrow}$ 线性分类器（向下馈送）</p>
</li>
<li><p>卷积网络：通过许多不同层计算由数据驱动的某种类型的特征表示，然后为整个网络训练整个权重</p>
</li>
</ul>
<hr>
<h3 id="Lecture-4-Introduction-to-Neural-Networks"><a href="#Lecture-4-Introduction-to-Neural-Networks" class="headerlink" title="Lecture 4 | Introduction to Neural Networks"></a>Lecture 4 | Introduction to Neural Networks</h3><ul>
<li><p>计算图：得到任意复杂函数的解析梯度</p>
<ul>
<li>用计算图来表示任何函数，图的节点为我们经历的计算步骤</li>
</ul>
</li>
<li><p>反向传播：递归的使用链式法则来计算图中每个变量的梯度</p>
<ul>
<li>上游梯度下降 乘以 局部梯度 以获得 相对输入的梯度</li>
<li>可以对任何你想要的节点进行分组，使其成为更复杂的节点（只要能写出局部梯度）（sigmoid）</li>
<li>变量为矢量 $\rightarrow$ 雅克比矩阵，核心公式为 $\frac{\partial f}{\partial x}=\sum<em>{i} \frac{\partial f}{\partial q</em>{i}} \cdot \frac{\partial q_{i}}{\partial x}$</li>
<li><p>e.g.<br>如果有：</p>
<script type="math/tex; mode=display">
\begin{array}{c}
q=W \cdot x=\left(\begin{array}{c}
W_{1,1} x_{1}+\cdots+W_{1, n} x_{n} \\
\vdots \\
W_{n, 1} x_{1}+\cdots+W_{n, n} x_{n}
\end{array}\right) \\
f(q)=\|q\|^{2}=q_{1}^{2}+\cdots+q^{2}
\end{array}</script><p>则有：</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\frac{\partial f}{\partial q_{i}}=2 q_{i} \\
\nabla_{q} f=2 q
\end{array}</script><script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial q_{k}}{\partial W_{i, j}} & =\mathbf{1}_{k=i} x_{j} \\
\frac{\partial f}{\partial W_{i, j}} & =\sum_{k} \frac{\partial f}{\partial q_{k}} \frac{\partial q_{k}}{\partial W_{i, j}} \\
& =\sum_{k}\left(2 q_{k}\right)\left(\mathbf{1}_{k=i} x_{j}\right)
\end{aligned} \\
\nabla_{W} f=2 q \cdot x^T</script><script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial q_{k}}{\partial x_{i}} & =W_{k, i} \\
\frac{\partial f}{\partial x_{i}} & =\sum_{k} \frac{\partial f}{\partial q_{k}} \frac{\partial q_{k}}{\partial x_{i}} \\
& =\sum_{k} 2 q_{k} W_{k, i}
\end{aligned} \\
\nabla_{x} f=2 W^T \cdot q</script></li>
<li><p>始终检查:关于变量的梯度应该与变量具有相同的形状</p>
</li>
</ul>
</li>
<li>程序:对于每一个门（节点），计算本地梯度并和上游梯度链接，实现一个前向函数和一个后向函数（API）<ul>
<li>正向传递：一个计算该节点输出的函数，并保存输入的值</li>
<li>反向传递：通过上游梯度和已有的值使用链式法则计算梯度</li>
</ul>
</li>
<li><p>前向传递通过迭代图中的所有节点来得到整个图（拓扑顺序添加节点）并保存中间值，然后通过反向顺序通过所有节点，在每一个节点上调用后向函数</p>
</li>
<li><p>神经网络：在另一个之上进行非线性变换并线性堆叠（多层网络）</p>
<script type="math/tex; mode=display">
(Before)\ Linear\ score\ function:  f=W x \\
\downarrow \\
(Now)\ 2-layer\ Neural\ Network  \quad f=W_{2} \max \left(0, W_{1} x\right)</script></li>
<li><p>多层神经网络：类比生物神经网络，但简化得多</p>
</li>
<li>完全连接层</li>
<li>每一层隐藏层类比一组神经元</li>
</ul>
<hr>
<h3 id="作业1"><a href="#作业1" class="headerlink" title="作业1"></a>作业1</h3><hr>
<h3 id="Lecture-5-Convolutional-Neural-Networks"><a href="#Lecture-5-Convolutional-Neural-Networks" class="headerlink" title="Lecture 5 | Convolutional Neural Networks"></a>Lecture 5 | Convolutional Neural Networks</h3><ul>
<li>全连接层: 32*32*3 的矢量（图片） $\stackrel{拉伸}{\longrightarrow}$ 3072 的矢量</li>
<li>卷积层：要保留矢量的空间结构（上一行的例子中为三维），输出：激活图<ul>
<li>权重：小过滤器（如5*5*3），“在空间上画过图像并计算每个空间位置的点积”，总是拓展输入体积的全部深度</li>
<li>叠加在图像的一个空间位置上，然后做点积（将所有相应的值相乘）</li>
<li>将过滤器居中放置在输入体积的每个像素的顶部，最后输出 28*28*1 的激活图 （过滤器划过整个图）</li>
<li>多个相同维度的激活器，然后叠加求得的激活图，输出的深度为激活器的数目</li>
<li>我们称该层为卷积层，因为它与两个信号的卷积有关:<br><script type="math/tex">f[x, y] * g[x, y]=\sum_{n_{1}=-\infty}^{\infty} \sum_{n_{2}=-\infty}^{\infty} f\left[n_{1}, n_{2}\right] \cdot g\left[x-n_{1}, y-n_{2}\right]</script>滤波器与信号(图像)的元素乘法和</li>
<li>这种计算公式 $\rightarrow$ 卷积的标准定义，但实际计算我们仍用过滤器在空间上划动到图像上，并且计算各位置的点积</li>
</ul>
</li>
<li>图片 $\rightarrow$ 低级特征 $\rightarrow$ 中级特征 $\rightarrow$ 高级特征 $\rightarrow$ 线性分类器</li>
<li>图片N，过滤器F，步长stride，填充层数pad，则输出：$(N+2*pad-F)/stride+1$，若为小数，则步长不适合，步长不适合时，可以进行边缘0填充</li>
<li>通常横竖处理相同的步长，通常处理的都是方形区域</li>
<li>高步长 $\rightarrow$ 向下取样</li>
<li>零填充：可以保持和输入一样的大小（否则在深层网络中尺寸会快速缩减 （丢失信息））</li>
<li>常见过滤器尺寸：3*3（填充一圈0），5*5（填充两圈0），7*7（填充三圈0）</li>
<li>参数数量：过滤器有几个数 + 1（偏差项）</li>
<li>过滤器数量 K 通常是 2 的幂，e.g. 32，64，128…</li>
<li>1 * 1 的过滤器：会遍历深度并加权计算，也很有意义</li>
<li>“5x5过滤器” -&gt; “每个神经元5 * 5个感受野”</li>
<li>池化层<ul>
<li>使表示更小，更易于管理</li>
<li>独立操作每个激活映射</li>
<li>功能：只是下采样</li>
<li>深度不变</li>
<li>通常设置步幅以保证不重叠</li>
</ul>
</li>
<li>最大池化：映射时不做点积，而是取其中的最大值（通常效果更好）<ul>
<li>给出一个信号，表明该过滤器在此图像中的任何位置触发了多少</li>
</ul>
</li>
<li>通常人们不会真正对池化层进行零填充，只是下采样</li>
<li><p>趋势：更小的过滤器，更深的架构</p>
</li>
<li><p>卷积网络（ConvNets）堆叠卷积层（CONV）、池化层（POOL）、全连接层（FC），</p>
</li>
<li><p>趋势：取消POOL/FC层(只是CONV层)</p>
</li>
<li>典型的架构看起来像<script type="math/tex; mode=display">
[(convl - relu)*N-POOL?] {}^{*} M-(FC-RELU)*K,SOFTMAX</script>其中 $\mathrm{N}$ 通常高达$\sim$ 5， $\mathrm{M}$ 很大，$0&lt;=\mathrm{K}&lt;=2$</li>
</ul>
<hr>
<h3 id="Lecture-6-Training-Neural-Networks-I"><a href="#Lecture-6-Training-Neural-Networks-I" class="headerlink" title="Lecture 6 | Training Neural Networks I"></a>Lecture 6 | Training Neural Networks I</h3><ul>
<li><p>小批量随机梯度下降<br>步骤：</p>
<ol>
<li>采样一批数据</li>
<li>通过计算图或神经网络转发它，获得Loss</li>
<li>通过网络反向传播计算梯度</li>
<li>使用梯度更新网络中的参数和权重</li>
</ol>
</li>
<li><p>训练神经网络</p>
</li>
<li><p>Part1 首次设置</p>
<ul>
<li>激活函数，预处理，权重初始化，正则化，梯度检查</li>
</ul>
</li>
<li><p>Part2 训练动态</p>
<ul>
<li>监督学习过程，参数更新规则，超参数优化</li>
</ul>
</li>
<li><p>Part3 评估</p>
<ul>
<li>模型集成</li>
</ul>
</li>
</ul>
<ol>
<li><p>激活函数：</p>
<ul>
<li><p>Sigmiod： $\sigma(x)=1 /\left(1+e^{-x}\right)$</p>
<ul>
<li>优点<ul>
<li>将数字压缩到[0,1]范围</li>
<li>这在历史上很受欢迎，因为它们可以很好地解释为神经元的饱和“放电率”</li>
</ul>
</li>
<li>缺点<ul>
<li>饱和神经元会消除梯度：此函数梯度在远离0的地方梯度趋于0，上游梯度传递到这之后就因链式法则乘0而为0了，这消除了梯度流，并且将有一个0梯度向下传递到下游节点</li>
<li>此函数输出不是以0为中心（均值）的：x均为正的后果：w的梯度总是全正或全负，会使效率降低（限制了梯度下降方向）</li>
<li>exp计算代价有点昂贵 </li>
</ul>
</li>
</ul>
</li>
<li><p>tanh</p>
<ul>
<li>优点<ul>
<li>将数字压缩到[-1,1]范围</li>
<li>0为中心（好！）</li>
</ul>
</li>
<li>缺点<ul>
<li>仍会消除梯度</li>
</ul>
</li>
</ul>
</li>
<li><p>ReLU： $f(x) = max(0, x)$</p>
<ul>
<li>优点<ul>
<li>在正区域不会饱和</li>
<li>计算简单</li>
<li>收敛速度快（比上面两个快）</li>
<li>比sigmiod在生物学上更合理</li>
</ul>
</li>
<li>缺点<ul>
<li>不以0为中心</li>
<li>负数时仍然是饱和的，会消除梯度（会出现一直由于梯度是0而不更新的‘dead ReLU’）</li>
</ul>
</li>
<li>人们喜欢用小的正初始值来初始化ReLU以增加其在初始化时的活跃性并获得一些更新（偏向于开始时触发更多的ReLU）</li>
</ul>
</li>
<li><p>Leaky ReLU $f(x) = max(0.01x,x)$</p>
<ul>
<li>优点<ul>
<li>在所有区域都不会饱和</li>
<li>计算简单</li>
<li>收敛速度快（比上面两个快）</li>
</ul>
</li>
</ul>
</li>
<li><p>参数整流器（Parametric Rectifier）（PReLU） $f(x) = max(\alpha x, x)$</p>
<ul>
<li>把 $\alpha$ 当成参数，通过训练（反向传播和学习）找到最优解</li>
</ul>
</li>
<li><p>指数线性单元（ELU）</p>
<script type="math/tex; mode=display">
 f(x)=\left\{\begin{array}{ll}
 x & \text { if } x>0 \\
 \alpha(\exp (x)-1) & \text { if } x \leq 0
 \end{array}\right.</script><ul>
<li>优点<ul>
<li>更接近零均值输出</li>
<li>对噪声有更强的鲁棒性</li>
</ul>
</li>
<li>介于ReLU和Leaky RelU之间，接近0均值输出，但仍具有饱和行为</li>
</ul>
</li>
<li><p>最大神经元（MaxOut） $\max \left(w<em>{1}^{T} x+b</em>{1}, w<em>{2}^{T} x+b</em>{2}\right)$</p>
<ul>
<li>不具备点积的基本形式 $\rightarrow$ 非线性</li>
<li>不会饱和也不会死亡</li>
<li>缺点<ul>
<li>参数翻倍了</li>
</ul>
</li>
</ul>
</li>
<li><p>在实践中：</p>
<ul>
<li>使用ReLU，（通用经验，最标准的，通常效果很好），注意训练步长（学习率）</li>
<li>可以尝试高级的激活函数，如 Leaky RELU / Maxout / ELU</li>
<li>也可以尝试tanh，但通常没有上面几种好</li>
<li>不要使用Sigmoid</li>
</ul>
</li>
</ul>
</li>
<li><p>数据预处理</p>
<ul>
<li>i</li>
</ul>
</li>
</ol>
<hr>
<h3 id="Lecture-7-Training-Neural-Networks-II"><a href="#Lecture-7-Training-Neural-Networks-II" class="headerlink" title="Lecture 7 | Training Neural Networks II"></a>Lecture 7 | Training Neural Networks II</h3><hr>
<h3 id="Lecture-8-Deep-Learning-Software"><a href="#Lecture-8-Deep-Learning-Software" class="headerlink" title="Lecture 8 | Deep Learning Software"></a>Lecture 8 | Deep Learning Software</h3><hr>
<h3 id="Lecture-9-CNN-Architectures"><a href="#Lecture-9-CNN-Architectures" class="headerlink" title="Lecture 9 | CNN Architectures"></a>Lecture 9 | CNN Architectures</h3><hr>
<h3 id="Lecture-10-Recurrent-Neural-Networks"><a href="#Lecture-10-Recurrent-Neural-Networks" class="headerlink" title="Lecture 10 | Recurrent Neural Networks"></a>Lecture 10 | Recurrent Neural Networks</h3><hr>
<h3 id="Lecture-11-Detection-and-Segmentation"><a href="#Lecture-11-Detection-and-Segmentation" class="headerlink" title="Lecture 11 | Detection and Segmentation"></a>Lecture 11 | Detection and Segmentation</h3><hr>
<h3 id="Lecture-12-Visualizing-and-Understanding"><a href="#Lecture-12-Visualizing-and-Understanding" class="headerlink" title="Lecture 12 | Visualizing and Understanding"></a>Lecture 12 | Visualizing and Understanding</h3><hr>
<h3 id="Lecture-13-Generative-Models"><a href="#Lecture-13-Generative-Models" class="headerlink" title="Lecture 13 | Generative Models"></a>Lecture 13 | Generative Models</h3><hr>
<h3 id="Lecture-14-Deep-Reinforcement-Learning"><a href="#Lecture-14-Deep-Reinforcement-Learning" class="headerlink" title="Lecture 14 | Deep Reinforcement Learning"></a>Lecture 14 | Deep Reinforcement Learning</h3><hr>
<h3 id="Lecture-15-Efficient-Methods-and-Hardware-for-Deep-Learning"><a href="#Lecture-15-Efficient-Methods-and-Hardware-for-Deep-Learning" class="headerlink" title="Lecture 15 | Efficient Methods and Hardware for Deep Learning"></a>Lecture 15 | Efficient Methods and Hardware for Deep Learning</h3><hr>
<h3 id="Lecture-16-Adversarial-Examples-and-Adversarial-Training"><a href="#Lecture-16-Adversarial-Examples-and-Adversarial-Training" class="headerlink" title="Lecture 16 | Adversarial Examples and Adversarial Training"></a>Lecture 16 | Adversarial Examples and Adversarial Training</h3>
                
                <hr>
                <!-- Pager -->
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2023/03/09/实现微信与 GPT - 3 对话/" data-toggle="tooltip" data-placement="top" title="实现微信与GPT-3对话">&larr; Previous Post
		<br>
		<span><font size="2" face="Calibri" color="grey">实现微信与GPT-3对话</font></span>
	       </a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2023/02/26/一般专业课评价/" data-toggle="tooltip" data-placement="top" title="一般专业课评价">Next Post &rarr;
		<br>
		<span><font size="2" face="Calibri" color="grey">一般专业课评价</font></span>
	        </a>
                    </li>
                    
                </ul>

                <!-- tip start -->
                

                
                <div class="comment_notes">
                    <p>
                        by Tan
                    </p>
                </div>
                
                <!-- tip end -->

                <!-- Music start-->
                
                <!-- Music end -->

                <!-- Sharing -->
                
                <!-- Sharing -->

                <!-- gitment start -->
                
                <!-- gitment end -->

                <!-- 来必力City版安装代码 -->
                
                <!-- City版安装代码已完成 -->

                <!-- disqus comment start -->
                
                <!-- disqus comment end -->
            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

    
      
        <aside id="sidebar">
          <div id="toc" class="toc-article">
          <strong class="toc-title">Contents</strong>
          
            
              <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-1-Introduction-to-Convolutional-Neural-Networks-for-Visual-Recognition"><span class="toc-nav-text">Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-2-Image-Classification"><span class="toc-nav-text">Lecture 2 | Image Classification</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-3-Loss-Functions-and-Optimization"><span class="toc-nav-text">Lecture 3 | Loss Functions and Optimization</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-4-Introduction-to-Neural-Networks"><span class="toc-nav-text">Lecture 4 | Introduction to Neural Networks</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#作业1"><span class="toc-nav-text">作业1</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-5-Convolutional-Neural-Networks"><span class="toc-nav-text">Lecture 5 | Convolutional Neural Networks</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-6-Training-Neural-Networks-I"><span class="toc-nav-text">Lecture 6 | Training Neural Networks I</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-7-Training-Neural-Networks-II"><span class="toc-nav-text">Lecture 7 | Training Neural Networks II</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-8-Deep-Learning-Software"><span class="toc-nav-text">Lecture 8 | Deep Learning Software</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-9-CNN-Architectures"><span class="toc-nav-text">Lecture 9 | CNN Architectures</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-10-Recurrent-Neural-Networks"><span class="toc-nav-text">Lecture 10 | Recurrent Neural Networks</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-11-Detection-and-Segmentation"><span class="toc-nav-text">Lecture 11 | Detection and Segmentation</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-12-Visualizing-and-Understanding"><span class="toc-nav-text">Lecture 12 | Visualizing and Understanding</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-13-Generative-Models"><span class="toc-nav-text">Lecture 13 | Generative Models</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-14-Deep-Reinforcement-Learning"><span class="toc-nav-text">Lecture 14 | Deep Reinforcement Learning</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-15-Efficient-Methods-and-Hardware-for-Deep-Learning"><span class="toc-nav-text">Lecture 15 | Efficient Methods and Hardware for Deep Learning</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Lecture-16-Adversarial-Examples-and-Adversarial-Training"><span class="toc-nav-text">Lecture 16 | Adversarial Examples and Adversarial Training</span></a></li></ol>
            
          
          </div>
        </aside>
      
    

                
            <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
                        
                    </div>
                </section>
                

            </div>
			
			<div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">
				
				<br>
				<br>

				<script src="https://utteranc.es/client.js"
						repo="Master-Tan/Master-Tan.github.io"
						issue-term="pathname"
						label="Comment"
						theme="github-light"
						crossorigin="anonymous"
						async>
				</script>
			</div>
        </div>
    </div>
</article>




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'left',
          icon: 'ℬ'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>


<style  type="text/css">
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">

                
                    <li>
                        <a target="_blank"  href="https://github.com/Master-Tan">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://twitter.com/None">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://www.facebook.com/None">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                

                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Tan 2023 | Powered by 
                    <a href="https://github.com/Master-Tan/Master-Tan.github.io" target="_blank" rel="noopener">
                        <i>Tan's Blog</i>
                    </a>
                </p>
            </div>
        </div>
    </div>

</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>


<!-- Search -->

<script src="/js/search.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://master-tan.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'UA-XXXXXXXX-X';
    var _gaDomain = 'yoursite';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Baidu Tongji -->


<!-- Search -->

    <script type="text/javascript">      
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
    var path = "/" + search_path;
    searchFunc(path, 'local-search-input', 'local-search-result');
    </script>


<!-- busuanzi -->
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>






	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>

    
        <!-- background effects line -->
        

        
            <script type="text/javascript" src="/js/mouse-click.js" content='[&quot;Sunny&quot;, &quot;💖&quot;, &quot;Sunny&quot;, &quot;🧡&quot;, &quot;Sunny&quot;, &quot;💛&quot;, &quot;Sunny&quot; , &quot;💚&quot;, &quot;Sunny&quot;, &quot;💙&quot;, &quot;Sunny&quot;, &quot;💜&quot;, &quot;Sunny&quot;, &quot;😍&quot;]' color='[&quot;rgb(255, 0, 0)&quot; ,&quot;rgb(255, 0, 0)&quot; ,&quot;rgb(255, 125, 0)&quot; ,&quot;rgb(255, 125, 0)&quot; ,&quot;rgb(255, 255, 0)&quot; ,&quot;rgb(255, 255, 0)&quot; ,&quot;rgb(0, 255, 0)&quot; ,&quot;rgb(0, 255, 0)&quot; ,&quot;rgb(0, 255, 255)&quot; ,&quot;rgb(0, 255, 255)&quot; ,&quot;rgb(0, 0, 255)&quot; ,&quot;rgb(0, 0, 255)&quot; ,&quot;rgb(255, 0, 255)&quot; ,&quot;rgb(255, 0, 255)&quot;]'></script>
        

        <!-- background effects end -->
    

    <!--<script size="50" alpha='0.3' zIndex="-999" src="/js/ribbonStatic.js"></script>-->
    
        <script src="/js/ribbonDynamic.js"></script>
    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>
