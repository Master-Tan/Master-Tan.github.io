<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="baidu-site-verification" content="093lY4ziMu" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="description" content="Tan&#39;s Blog">
    <meta name="keyword"  content="Hello world">
    <link rel="shortcut icon" href="/img/ironman-draw.png">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <!--<link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>-->
    <title>
        
          RLHF学习笔记 - Tan&#39;s Blog
        
    </title>

    <link rel="canonical" href="https://master-tan.github.io/2023/07/13/RLHF学习笔记/">

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS --> 
    
        
<link rel="stylesheet" href="/css/dusign-light.css">

        
<link rel="stylesheet" href="/css/dusign-common-light.css">

        
<link rel="stylesheet" href="/css/font-awesome.css">

        
<link rel="stylesheet" href="/css/toc.css">

        <!-- background effects end -->
    
    
    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    
<link rel="stylesheet" href="/css/widget.css">


    
<link rel="stylesheet" href="/css/rocket.css">


    
<link rel="stylesheet" href="/css/signature.css">


    
<link rel="stylesheet" href="/css/fonts.googleapis.css">


    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">

    <!-- photography -->
    
<link rel="stylesheet" href="/css/photography.css">


    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- background effects start -->
    
    <!-- background effects end -->

	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            
                background-image: linear-gradient(rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3)), url('../../../../img/default.jpg')
                /*post*/
            
        
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
                            
                              <a class="tag" href="/tags/#暑期实习" title="暑期实习">暑期实习</a>
                            
                        </div>
                        <h1>RLHF学习笔记</h1>
                        <h2 class="subheading">暑期实习笔记-3</h2>
                        <span class="meta">
                            Posted by Tan on
                            2023-07-13
                        </span>

	       
                            <div class="blank_box"></div>
                            <span class="meta">
                                 <span class="post-count">2.8k</span> Words
                            </span>
                            <div class="blank_box"></div>
                            <!-- 不蒜子统计 start -->
                            <span class="meta">
                                Viewed <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span> Times
                            </span>
                            <!-- 不蒜子统计 end -->
                        

                    </div>
                

                </div>
            </div>
        </div>      
    </div>

    
    <div class="waveWrapper">
        <div class="wave wave_before" style="background-image: url('/img/wave-light.png')"></div>
        <div class="wave wave_after" style="background-image: url('/img/wave-light.png')"></div>
    </div>
    
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Tan&#39;s Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        	<li>
                          	  <a href="/archive/">Archives</a>
                        	</li>
                        
                    

                        
                        	<li>
                          	  <a href="/about/">About Tan</a>
                        	</li>
                        
                    

                        
                        	<li>
                          	  <a href="/tags/">Tags</a>
                        	</li>
                        
                    

                        
                    

                        
                    

                        
                    

                        
                    
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    <!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>RLHF（Reinforcement Learning from Human Feedback）：即使用<strong>强化学习</strong>的方法，通过<strong>人类反馈</strong>来指导智能系统的行为。在RLHF中，人类提供关于智能系统行为的反馈，比如哪些行为是正确的，哪些行为是错误的。根据这些反馈，智能系统可以逐步改进自己的行为策略，在未来采取更加明智的行为。这种方法减轻了传统强化学习中需要大量试错的问题，使得智能系统更加高效、快速地学习任务</p>
<h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><p><strong>第一种情况：无法创建好的损失函数</strong><br>在某些任务中，由于任务复杂性或主观性，难以明确定义一个可用作损失函数的标准。在这种情况下，使用人类反馈进行强化学习可以是一个更合适的选择。通过让人类提供关于系统行为的反馈，可以指导模型生成更符合期望的输出。例如，在语言生成任务中，人们很难定义出“正确”的输出，因为输出的灵活性和多样性很高。通过让人类选择他们认为有趣的输出，并将其用作正面反馈，同时选择不有趣或令人讨厌的输出作为负面反馈，模型可以逐渐学习生成更有趣的输出。</p>
<p><strong>第二种情况：难以对生产数据进行标记</strong><br>在某些情况下，生产数据可能非常庞大，手动标记数据需要耗费大量时间和成本，或者标记数据的困难性可能需要专业知识或主观判断。在这种情况下，使用人类反馈进行强化学习可以作为一种无监督学习方法。模型与生产数据进行交互，并从人类反馈中学习，以逐渐提高性能，而无需标记数据。例如，在聊天机器人应用中，模型可以生成回答并让人类评审员提供反馈。这些反馈可以作为正面或负面奖励，指导模型如何更好地回答问题。通过不断的交互和反馈，模型可以逐步改善输出结果，以满足实际需求。</p>
<p>总体而言，使用人类反馈进行强化学习（RLHF）可以解决无法创建好的损失函数或难以标记生产数据的问题，并通过人类反馈指导模型的学习和改进。这种方法可以使模型逐步提高性能，同时减少对人工标记数据的需求。</p>
<h1 id="样例代码"><a href="#样例代码" class="headerlink" title="样例代码"></a>样例代码</h1><ul>
<li><strong>DeepSpeed-Chat</strong> <a href="https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat" target="_blank" rel="noopener">https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat</a></li>
<li><strong>PaLM-rlhf-pytorch</strong> <a href="https://github.com/lucidrains/PaLM-rlhf-pytorch" target="_blank" rel="noopener">https://github.com/lucidrains/PaLM-rlhf-pytorch</a></li>
<li><strong>Open-Assistant</strong> <a href="https://github.com/LAION-AI/Open-Assistant" target="_blank" rel="noopener">https://github.com/LAION-AI/Open-Assistant</a></li>
<li><strong>Transformer Reinforcement Learning X</strong> <a href="https://github.com/CarperAI/trlx" target="_blank" rel="noopener">https://github.com/CarperAI/trlx</a></li>
<li><a href="https://github.com/anthropics/hh-rlhf" target="_blank" rel="noopener">https://github.com/anthropics/hh-rlhf</a></li>
</ul>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><ul>
<li><a href="./Training language models to follow instructions.pdf">Training language models to follow instructions</a></li>
<li><a href="./Learning to summarize from human feedback.pdf">Learning to summarize from human feedback</a></li>
</ul>
<h1 id="方法流程"><a href="#方法流程" class="headerlink" title="方法流程"></a>方法流程</h1><ol>
<li>预训练语言模型（LM）</li>
<li>聚合问答数据并训练一个奖励模型（reward model）</li>
<li>使用 RL 对 LM 进行微调（Fine-tuning）</li>
</ol>
<p><img src="ChatGPT_Diagram.svg"></p>
<h2 id="预训练语言模型（LM）"><a href="#预训练语言模型（LM）" class="headerlink" title="预训练语言模型（LM）"></a>预训练语言模型（LM）</h2><p>在使用RLHF方法进行文本生成之前，需要获得一个语言模型。可以选择从头开始训练模型，也可以使用预训练的模型，如GPT-3。</p>
<p>如果已经拥有一个预训练的语言模型，可以选择进行监督式微调（SFT），这是一个可选的步骤。在SFT中，需要准备一些人工标注的（输入，输出）文本对，并使用这些数据对已有的语言模型进行微调。监督式微调有助于提高模型在特定任务上的性能表现，为RLHF提供高质量的初始化。</p>
<p>在使用SFT进行微调时，可以使用标准的监督学习方法。将人工标注的（输入，输出）文本对作为训练样本，使用反向传播算法来更新模型参数。通过这种方式，可以使模型更好地理解每个输入与其对应的输出，并对其进行相应的操作。此外，SFT还可以有效地减少模型顺序执行时出现的错误，从而提高生成结果的质量。</p>
<p>完成监督式微调和其他必要的步骤后，将获得一个训练好的语言模型（LM）。这个训练好的LM将作为主模型，并将用于使用RLHF方法进行进一步的微调。</p>
<p>由于已经使用人工标注的数据对LM进行了微调，现在的LM已经可以更好地理解每个输入与其对应的输出。这使得可以更加高效地使用RLHF方法进行微调。在后续的步骤中，将使用RLHF算法来进一步训练这个已经微调好的LM，从而生成更高质量、更准确的文本生成结果。<br><img src="pretraining.png"></p>
<h2 id="聚合问答数据并训练一个奖励模型（Reward-Model，RM）"><a href="#聚合问答数据并训练一个奖励模型（Reward-Model，RM）" class="headerlink" title="聚合问答数据并训练一个奖励模型（Reward Model，RM）"></a>聚合问答数据并训练一个奖励模型（Reward Model，RM）</h2><p>在这一步中，需要收集一个数据集，其中包含（输入文本，输出文本，奖励）三元组。</p>
<p>数据收集的流程为：首先使用输入文本数据（如果是生产数据，则效果更好），将其通过模型生成相应的文本输出。然后，让人类专家对这个生成的输出结果进行评估，并为其打分或给予奖励信号。这些奖励信号将被用来指导RL算法的学习过程，从而帮助我们进一步微调模型，生成更好的文本输出结果。</p>
<p>为了确保数据集的质量，需要选择高质量、多样化的输入文本，并且尽可能地避免使用重复的或过于简单的语句。同时，也应该选择具有代表性的人类专家来评估生成的输出结果，并为其提供准确的评价或奖励信号。这样可以确保收集到的数据集可以在后面的RLHF微调中有效地提高模型的性能表现。</p>
<p>通常情况下，奖励信号使用0到5之间的整数进行表示，其中5表示最高的奖励，0则表示最低的奖励。这种奖励信号可以让RLHF算法更好地理解生成的文本输出结果，并且在后续的微调阶段中有助于提高模型的性能表现。</p>
<p>当然，有时候也可以使用简单的二元奖励信号，例如使用“赞”或“踩”符号来表示给予的奖励或惩罚。虽然这种方法可能比使用整数奖励信号更加简化，但它可能会降低收集数据集的可靠性，因为仅仅给出一个简单的奖励信号往往无法充分反映出生成的文本质量的差异。</p>
<p>我们可以使用这个新的数据集来训练一个奖励模型，该模型可以将（输入文本，输出文本）作为输入，并返回一个奖励的标量值作为输出。这个奖励模型可以模拟人类专家对生成的文本质量的评价和奖励，从而可以在没有人类参与的情况下进行RLHF训练。</p>
<p>使用这个奖励模型，我们可以设计一个离线的RLHF算法，该算法可以通过先使用语言模型生成一组文本输出，然后使用奖励模型评估这些输出的质量，最后使用RL算法根据奖励信号微调模型。这样，我们就可以在没有人类参与的情况下，自动地对模型进行优化和微调，以提高其生成的文本质量。</p>
<p>在训练奖励模型时，需要保证数据集的质量和多样性，从而确保模型可以准确地学习到人类专家的评价和奖励行为。此外，还需要确保奖励模型具有足够的泛化能力，从而可以在不同领域和任务中进行有效的模型微调。</p>
<p><img src="reward-model.png"></p>
<h2 id="用强化学习（RL）方式微调-LM"><a href="#用强化学习（RL）方式微调-LM" class="headerlink" title="用强化学习（RL）方式微调 LM"></a>用强化学习（RL）方式微调 LM</h2><p>我们将使用奖励模型返回的奖励信号来训练主模型，也就是我们训练好的语言模型。然而，由于奖励信号是非可导的，我们需要使用RL算法（如：PPO算法）来构建一个可以反向传播到语言模型的损失函数。</p>
<p>具体来说，我们可以使用强化学习中的Q-learning算法来实现这个过程。在RLHF算法中，我们将把语言模型看作是我们的“智能体”，其任务是产生高质量的文本输出，奖励模型将根据人类专家的评价和反馈来分配奖励信号。在每次迭代中，我们都会计算奖励模型返回的奖励信号，将其作为Q-learning算法的奖励反馈，并使用奖励信号来更新语言模型的策略，以便在下一次生成文本时产生更好的结果。</p>
<p>通过不断地迭代这个过程，我们可以逐步优化语言模型的性能，使其在生成文本时更加准确和自然。同时，借助RL算法的强大功能，可以有效地解决传统优化方法无法解决的问题，例如生成文本中的不连贯性和模型的过拟合问题。</p>
<p>在流程的开始，我们将创建一个精确复制我们的语言模型，并冻结它的可训练参数。这个复制的模型可以帮助防止可训练的语言模型完全改变其权重并开始输出无意义的文本，从而影响奖励模型的训练。</p>
<p>这也是为什么我们要计算冻结和非冻结语言模型的文本输出概率之间的KL散度损失。这个KL损失将被加到由奖励模型产生的奖励之中。实际上，如果您正在进行在线学习的模型训练过程中，可以直接用人工鉴定的奖励分数来替代奖励模型。</p>
<p>有了奖励和KL损失，我们现在可以应用RL算法使奖励损失变得可导。为什么奖励不可导呢？因为它是由奖励模型根据文本生成的结果计算出来的。这个文本是通过对语言模型的输出对数概率进行解码得到的。该解码过程是不可导的。</p>
<p><img src="rlhf.png"></p>
<h3 id="近端策略优化算法-Proximal-Policy-Optimization，PPO-介绍"><a href="#近端策略优化算法-Proximal-Policy-Optimization，PPO-介绍" class="headerlink" title="近端策略优化算法 (Proximal Policy Optimization，PPO)  介绍"></a>近端策略优化算法 (Proximal Policy Optimization，PPO)  介绍</h3><p>。。。</p>
<h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><ul>
<li><p>从零实现ChatGPT——RLHF技术笔记 <a href="https://zhuanlan.zhihu.com/p/591474085" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/591474085</a></p>
</li>
<li><p>Illustrating Reinforcement Learning from Human Feedback (RLHF) <a href="https://huggingface.co/blog/rlhf" target="_blank" rel="noopener">https://huggingface.co/blog/rlhf</a></p>
</li>
<li><p>ChatGPT 背后的“功臣”——RLHF 技术详解 <a href="https://huggingface.co/blog/zh/rlhf" target="_blank" rel="noopener">https://huggingface.co/blog/zh/rlhf</a></p>
</li>
<li><p>从人类反馈中进行强化学习（RLHF）- 白话解释 <a href="https://zhuanlan.zhihu.com/p/631238431" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/631238431</a></p>
</li>
<li><p>详解大模型RLHF过程（配代码解读） <a href="https://zhuanlan.zhihu.com/p/624589622" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/624589622</a></p>
</li>
<li><p>深入理解强化学习 <a href="https://zhuanlan.zhihu.com/p/478594917" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/478594917</a></p>
</li>
<li><p>Introducing ChatGPT <a href="https://openai.com/blog/chatgpt" target="_blank" rel="noopener">https://openai.com/blog/chatgpt</a></p>
</li>
<li><p>2022 GPT 发展：ChatGPT成功面世，LLM 里程碑式胜利 <a href="https://zhuanlan.zhihu.com/p/608837650" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/608837650</a></p>
</li>
</ul>

                
                <hr>
                <!-- Pager -->
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2023/07/18/大三下总结/" data-toggle="tooltip" data-placement="top" title="大三下总结">&larr; Previous Post
		<br>
		<span><font size="2" face="Calibri" color="grey">大三下总结</font></span>
	       </a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2023/07/06/OpenStreetMap学习笔记/" data-toggle="tooltip" data-placement="top" title="OpenStreetMap学习笔记">Next Post &rarr;
		<br>
		<span><font size="2" face="Calibri" color="grey">OpenStreetMap学习笔记</font></span>
	        </a>
                    </li>
                    
                </ul>

                <!-- tip start -->
                

                
                <div class="comment_notes">
                    <p>
                        by Tan
                    </p>
                </div>
                
                <!-- tip end -->

                <!-- Music start-->
                
                <!-- Music end -->

                <!-- Sharing -->
                
                <!-- Sharing -->

                <!-- gitment start -->
                
                <!-- gitment end -->

                <!-- 来必力City版安装代码 -->
                
                <!-- City版安装代码已完成 -->

                <!-- disqus comment start -->
                
                <!-- disqus comment end -->
            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

    
      
        <aside id="sidebar">
          <div id="toc" class="toc-article">
          <strong class="toc-title">Contents</strong>
          
            
              <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#简介"><span class="toc-nav-text">简介</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#应用场景"><span class="toc-nav-text">应用场景</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#样例代码"><span class="toc-nav-text">样例代码</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#相关论文"><span class="toc-nav-text">相关论文</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#方法流程"><span class="toc-nav-text">方法流程</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#预训练语言模型（LM）"><span class="toc-nav-text">预训练语言模型（LM）</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#聚合问答数据并训练一个奖励模型（Reward-Model，RM）"><span class="toc-nav-text">聚合问答数据并训练一个奖励模型（Reward Model，RM）</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#用强化学习（RL）方式微调-LM"><span class="toc-nav-text">用强化学习（RL）方式微调 LM</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#近端策略优化算法-Proximal-Policy-Optimization，PPO-介绍"><span class="toc-nav-text">近端策略优化算法 (Proximal Policy Optimization，PPO)  介绍</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#参考文章"><span class="toc-nav-text">参考文章</span></a></li></ol>
            
          
          </div>
        </aside>
      
    

                
            <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
                        
                          <a class="tag" href="/tags/#暑期实习" title="暑期实习">暑期实习</a>
                        
                    </div>
                </section>
                

            </div>
			
			<div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">
				
				<br>
				<br>

				<script src="https://utteranc.es/client.js"
						repo="Master-Tan/Master-Tan.github.io"
						issue-term="pathname"
						label="Comment"
						theme="github-light"
						crossorigin="anonymous"
						async>
				</script>
			</div>
        </div>
    </div>
</article>




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'left',
          icon: 'ℬ'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>


<style  type="text/css">
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">

                
                    <li>
                        <a target="_blank"  href="https://github.com/Master-Tan">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://twitter.com/None">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://www.facebook.com/None">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                

                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Tan 2023 | Powered by 
                    <a href="https://github.com/Master-Tan/Master-Tan.github.io" target="_blank" rel="noopener">
                        <i>Tan's Blog</i>
                    </a>
                </p>
            </div>
        </div>
    </div>

</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>


<!-- Search -->

<script src="/js/search.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://master-tan.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'UA-XXXXXXXX-X';
    var _gaDomain = 'yoursite';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Baidu Tongji -->


<!-- Search -->

    <script type="text/javascript">      
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
    var path = "/" + search_path;
    searchFunc(path, 'local-search-input', 'local-search-result');
    </script>


<!-- busuanzi -->
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>






	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>

    
        <!-- background effects line -->
        

        
            <script type="text/javascript" src="/js/mouse-click.js" content='[&quot;Sunny&quot;, &quot;💖&quot;, &quot;Sunny&quot;, &quot;🧡&quot;, &quot;Sunny&quot;, &quot;💛&quot;, &quot;Sunny&quot; , &quot;💚&quot;, &quot;Sunny&quot;, &quot;💙&quot;, &quot;Sunny&quot;, &quot;💜&quot;, &quot;Sunny&quot;, &quot;😍&quot;]' color='[&quot;rgb(255, 0, 0)&quot; ,&quot;rgb(255, 0, 0)&quot; ,&quot;rgb(255, 125, 0)&quot; ,&quot;rgb(255, 125, 0)&quot; ,&quot;rgb(255, 255, 0)&quot; ,&quot;rgb(255, 255, 0)&quot; ,&quot;rgb(0, 255, 0)&quot; ,&quot;rgb(0, 255, 0)&quot; ,&quot;rgb(0, 255, 255)&quot; ,&quot;rgb(0, 255, 255)&quot; ,&quot;rgb(0, 0, 255)&quot; ,&quot;rgb(0, 0, 255)&quot; ,&quot;rgb(255, 0, 255)&quot; ,&quot;rgb(255, 0, 255)&quot;]'></script>
        

        <!-- background effects end -->
    

    <!--<script size="50" alpha='0.3' zIndex="-999" src="/js/ribbonStatic.js"></script>-->
    
        <script src="/js/ribbonDynamic.js"></script>
    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>
